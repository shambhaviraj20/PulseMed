{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pinecone import Pinecone, ServerlessSpec \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the PDF\n",
    "pdf_path = \"C:/Users/Sarthak/Downloads/harrison‚Äôs-principles-of-internal-medicine-21st-edition.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "# Extract data (list of Document objects)\n",
    "extracted_data = loader.load()\n",
    "\n",
    "# Split the extracted documents into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# Apply text splitting\n",
    "text_chunks = text_split(extracted_data)\n",
    "\n",
    "# Print a few chunks to verify\n",
    "print(text_chunks[:2])  # Print first two chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "print(PINECONE_API_KEY)  # Ensure it's set correctly\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define Index Name\n",
    "index_name = \"medbot\"\n",
    "\n",
    "\n",
    "# Check if Index Exists\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created new index: {index_name}\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Dont Run The Below Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "docsearch = Pinecone.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "print(PINECONE_API_KEY)  # Ensure it's set correctly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"medbot\",\n",
    "    embedding=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.4, max_tokens=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import speech_recognition as sr\n",
    "from deep_translator import GoogleTranslator  \n",
    "\n",
    "# ------------------------- Firebase Setup -------------------------\n",
    "def initialize_firebase():\n",
    "    cred = credentials.Certificate(\"C:/Users/Sarthak/OneDrive/Desktop/BITS/service_account_key.json\")\n",
    "\n",
    "    if not firebase_admin._apps:\n",
    "        firebase_admin.initialize_app(cred, {\n",
    "            'databaseURL': 'https://smart-box-4da35-default-rtdb.asia-southeast1.firebasedatabase.app'\n",
    "        })\n",
    "\n",
    "def get_patient_data():\n",
    "    ref = db.reference('patient')\n",
    "    data = ref.get()\n",
    "    return data.get('SOS', 'No SOS Message'), data.get('avgHeartRate', 'No Heart Rate Data'), data.get('avgTemperature', 'No Temperature Data')\n",
    "\n",
    "# ------------------------- Speech Recognition -------------------------\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"üé§ ‡§¨‡•ã‡§≤‡•á‡§Ç... (Speak something)\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        detected_text = recognizer.recognize_google(audio, language=\"hi\")  \n",
    "        print(f\"üó£ ‡§™‡§π‡§ö‡§æ‡§®‡§æ ‡§ó‡§Ø‡§æ: {detected_text}\")\n",
    "        return detected_text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"‚ùå ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§à (Could not understand audio)\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"‚ö† ‡§∏‡§∞‡•ç‡§µ‡§∞ ‡§∏‡•á ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ (Speech recognition service error)\")\n",
    "        return None\n",
    "\n",
    "# ------------------------- Translation -------------------------\n",
    "def translate_text(text):\n",
    "    translator = GoogleTranslator(source=\"auto\", target=\"en\")\n",
    "    translation = translator.translate(text)  \n",
    "    print(f\"‚úÖ Translated: {translation}\")\n",
    "    return translation  \n",
    "\n",
    "# ------------------------- Main Function -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_firebase()\n",
    "\n",
    "    choice = input(\"Enter 1 for Chat, 2 for Voice: \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        user_input = input(\"üìù Type your query: \")\n",
    "    elif choice == \"2\":\n",
    "        speech_text = recognize_speech()\n",
    "        user_input = translate_text(speech_text) if speech_text else \"No speech input provided\"\n",
    "    else:\n",
    "        print(\"‚ùå Invalid choice. Defaulting to Chat input.\")\n",
    "        user_input = input(\"üìù Type your query: \")\n",
    "\n",
    "    sos, heart_rate, temperature = get_patient_data()\n",
    "    final_prompt = f\"{user_input} what immediate medications should be taken? and my Heart Rate is {heart_rate} bpm and body temperature {temperature} ¬∞C \"\n",
    "\n",
    "    print(\"\\nüìù Generated Chatbot Prompt:\\n\", final_prompt)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": final_prompt })\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": final_prompt })\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "import random\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "twilio_sid = os.getenv(\"TWILIO_ACCOUNT_SID\")\n",
    "twilio_token = os.getenv(\"TWILIO_AUTH_TOKEN\")\n",
    "\n",
    "client = Client(twilio_sid, twilio_token)\n",
    "\n",
    "message = client.messages.create(\n",
    "\n",
    "  body=f\"A patient has the following issue:\\n{translated_speech}\\n His Collected Data:\\n Heart rate : {heart_rate}\\n Body Temperature : {temperature} ¬∞C \\n suggested advice :  {response['answer']} \",\n",
    "  from_='+18153840986',\n",
    "  to='+918766049932'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
